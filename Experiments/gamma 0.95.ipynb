{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.layers import Input,Dense\n",
    "from tensorflow.keras.models import Model\n",
    "import gym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import time "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "epsilon = 1  \n",
    "EPSILON_DECAY = 0.998 \n",
    "MIN_EPSILON = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make('LunarLander-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ActionValueNetwork:\n",
    "    def __init__(self, network_config):\n",
    "        self.state_dim = network_config.get(\"state_dim\")\n",
    "        self.num_hidden_units = network_config.get(\"num_hidden_units\")\n",
    "        self.num_actions = network_config.get(\"num_actions\")\n",
    "        self.step_size=network_config.get('step_size')\n",
    "    def create_model(self):\n",
    "        i = Input(shape=self.state_dim)\n",
    "        x = Dense(256, activation='relu')(i)\n",
    "        x = Dense(128, activation='relu')(x)\n",
    "        x = Dense(self.num_actions, activation='linear')(x)\n",
    "        model = Model(i, x)\n",
    "        model.compile(optimizer=Adam(lr=self.step_size),loss='mse')\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReplayBuffer:\n",
    "    def __init__(self, size, minibatch_size, seed):\n",
    "\n",
    "        self.buffer = []\n",
    "        self.minibatch_size = minibatch_size\n",
    "        self.rand_generator = np.random.RandomState(seed)\n",
    "        self.max_size = size\n",
    "\n",
    "    def append(self, state, action, reward, terminal, next_state):\n",
    "        \n",
    "        if len(self.buffer) == self.max_size:\n",
    "            del self.buffer[0]\n",
    "        self.buffer.append([state, action, reward, terminal, next_state])\n",
    "\n",
    "    def sample(self):\n",
    "       \n",
    "        idxs = self.rand_generator.choice(np.arange(len(self.buffer)), size=self.minibatch_size)\n",
    "        return [self.buffer[idx] for idx in idxs]\n",
    "\n",
    "    def size(self):\n",
    "        return len(self.buffer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Agent:\n",
    "    def __init__(self, agent_config):\n",
    "       \n",
    "        self.replay_buffer = ReplayBuffer(agent_config['replay_buffer_size'], \n",
    "                                          agent_config['minibatch_sz'], agent_config.get(\"seed\"))\n",
    "        self.network = ActionValueNetwork(agent_config['network_config'])\n",
    "        \n",
    "        self.model=self.network.create_model()\n",
    "        \n",
    "        self.target_model=self.network.create_model()\n",
    "        \n",
    "        self.num_actions = agent_config['network_config']['num_actions']\n",
    "        \n",
    "        self.num_replay = agent_config['num_replay_updates_per_step']\n",
    "        self.discount = agent_config['gamma']\n",
    "        \n",
    "        self.rand_generator = np.random.RandomState(agent_config.get(\"seed\"))\n",
    "        \n",
    "        self.last_state = None\n",
    "        self.last_action = None\n",
    "        self.epsilon = epsilon\n",
    "        self.sum_rewards = 0\n",
    "        self.episode_steps = 0\n",
    "\n",
    "    \n",
    "    def policy(self, state):\n",
    "     \n",
    "        action_values =self.model.predict(state)\n",
    "        if (np.random.uniform() < self.epsilon) or (action_values.all() == 0):\n",
    "            action = np.random.randint(0, env.action_space.n)\n",
    "        else:\n",
    "            action=np.argmax(action_values)\n",
    "        return action\n",
    "\n",
    "    \n",
    "    def agent_start(self):\n",
    "       \n",
    "        \n",
    "        self.sum_rewards = 0\n",
    "        self.episode_steps = 0\n",
    "        self.last_state = env.reset()\n",
    "        self.last_state = np.reshape(self.last_state,(-1,self.last_state.shape[0]))\n",
    "        self.last_action = self.policy(self.last_state)\n",
    "        return self.last_action\n",
    "\n",
    "\n",
    "    def agent_step(self, state,reward,terminal):\n",
    "      \n",
    "        \n",
    "        self.sum_rewards += reward\n",
    "        self.episode_steps += 1\n",
    "        \n",
    "        state = np.array([state])\n",
    "       \n",
    "     \n",
    "        action = self.policy(state)\n",
    "       \n",
    "        \n",
    "        \n",
    "\n",
    "       \n",
    "        self.replay_buffer.append(self.last_state, self.last_action, reward, terminal, state)\n",
    "       \n",
    "        if self.replay_buffer.size() > self.replay_buffer.minibatch_size:\n",
    "            self.target_model.set_weights(self.model.get_weights())\n",
    "            for _ in range(self.num_replay):\n",
    "                experiences = self.replay_buffer.sample()\n",
    "                self.agent_train(experiences)\n",
    "        \n",
    "        self.last_state = state\n",
    "        self.last_action = action\n",
    "       \n",
    "        \n",
    "        return action\n",
    "\n",
    "    \n",
    "    def agent_train(self,experiences):\n",
    "        states, actions, rewards, terminals, next_states = map(list, zip(*experiences))\n",
    "        states = np.concatenate(states)\n",
    "        next_states = np.concatenate(next_states)\n",
    "        rewards = np.array(rewards)\n",
    "        terminals = np.array(terminals)\n",
    "        batch_size1 = states.shape[0]\n",
    "        q_next_mat = self.target_model.predict(next_states)\n",
    "        \n",
    "        v_next_vec = np.max(q_next_mat, axis=1)*(1-terminals)\n",
    "        \n",
    "        target_vec = rewards + self.discount*v_next_vec\n",
    "       \n",
    "        q_mat = self.model.predict(states)\n",
    "      \n",
    "        batch_indices = np.arange(q_mat.shape[0])\n",
    "\n",
    "        X=states\n",
    "        q_mat[batch_indices,actions] = target_vec\n",
    " \n",
    "        self.model.fit(X,q_mat,batch_size=batch_size1,verbose=0,shuffle=False)\n",
    "        \n",
    "    def agent_message(self, message):\n",
    "        if message == \"get_sum_reward\":\n",
    "            return self.sum_rewards\n",
    "        else:\n",
    "            raise Exception(\"Unrecognized Message!\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_info = {\n",
    "             'network_config': {\n",
    "                 'state_dim': 8,\n",
    "                 'num_actions': 4,\n",
    "                 'step_size':1e-3\n",
    "             },\n",
    "             'replay_buffer_size': 50000,\n",
    "             'minibatch_sz': 64,\n",
    "             'num_replay_updates_per_step': 4,\n",
    "             'gamma': 0.95,\n",
    "             'seed': 0}\n",
    "EPISODES = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent=Agent(agent_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "reward_episode=[]\n",
    "no_episodes=[]\n",
    "episode_steps=[]\n",
    "eps_history=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode:  0 score:  -115.17095984196763 epsilon 0.83 steps 91\n",
      "episode:  1 score:  -94.78368746910266 epsilon 0.70 steps 86\n",
      "episode:  2 score:  -271.6819623466136 epsilon 0.60 steps 82\n",
      "episode:  3 score:  -44.363561492489836 epsilon 0.46 steps 133\n",
      "episode:  4 score:  -140.9167389738966 epsilon 0.37 steps 106\n",
      "episode:  5 score:  -270.37136693209436 epsilon 0.30 steps 106\n",
      "episode:  6 score:  13.416376741490794 epsilon 0.22 steps 157\n",
      "episode:  7 score:  -96.17115855063275 epsilon 0.19 steps 60\n",
      "episode:  8 score:  11.958474636660242 epsilon 0.16 steps 93\n",
      "episode:  9 score:  -505.7816597670661 epsilon 0.14 steps 81\n",
      "episode:  10 score:  -471.3396999477431 epsilon 0.11 steps 127\n",
      "episode:  11 score:  -147.31030553000284 epsilon 0.08 steps 141\n",
      "episode:  12 score:  -167.71087189354458 epsilon 0.06 steps 166\n",
      "episode:  13 score:  -146.8974771557461 epsilon 0.05 steps 71\n",
      "episode:  14 score:  -173.39529418595123 epsilon 0.04 steps 102\n",
      "episode:  15 score:  -175.19281870932997 epsilon 0.03 steps 204\n",
      "episode:  16 score:  -114.28528186955161 epsilon 0.02 steps 206\n",
      "episode:  17 score:  -31.87208890419734 epsilon 0.01 steps 132\n",
      "episode:  18 score:  -149.57195642219034 epsilon 0.01 steps 563\n",
      "episode:  19 score:  -91.87271411378522 epsilon 0.01 steps 1000\n",
      "episode:  20 score:  -156.5597962027561 epsilon 0.01 steps 1000\n",
      "episode:  21 score:  -88.5205424594497 epsilon 0.01 steps 1000\n",
      "episode:  22 score:  -515.1322744500776 epsilon 0.01 steps 941\n",
      "episode:  23 score:  -190.44588694374966 epsilon 0.01 steps 1000\n",
      "episode:  24 score:  -73.82752554699451 epsilon 0.01 steps 1000\n",
      "episode:  25 score:  -56.873707463841676 epsilon 0.01 steps 278\n",
      "episode:  26 score:  -190.15513904697772 epsilon 0.01 steps 627\n",
      "episode:  27 score:  -122.69529526037017 epsilon 0.01 steps 1000\n",
      "episode:  28 score:  -75.44828332553858 epsilon 0.01 steps 1000\n",
      "episode:  29 score:  -63.57068200864758 epsilon 0.01 steps 1000\n",
      "episode:  30 score:  -110.51693021433941 epsilon 0.01 steps 1000\n",
      "episode:  31 score:  -48.06230828928637 epsilon 0.01 steps 1000\n",
      "episode:  32 score:  -43.33477619054013 epsilon 0.01 steps 1000\n",
      "episode:  33 score:  -51.158677202506524 epsilon 0.01 steps 1000\n",
      "episode:  34 score:  -115.23811558064642 epsilon 0.01 steps 1000\n",
      "episode:  35 score:  -25.75519711984166 epsilon 0.01 steps 1000\n",
      "episode:  36 score:  -113.74743731294333 epsilon 0.01 steps 1000\n",
      "episode:  37 score:  -81.92497475833127 epsilon 0.01 steps 1000\n",
      "episode:  38 score:  -21.232544839780584 epsilon 0.01 steps 1000\n",
      "episode:  39 score:  -323.8692243556696 epsilon 0.01 steps 81\n",
      "episode:  40 score:  -42.36902778945438 epsilon 0.01 steps 1000\n",
      "episode:  41 score:  -87.33420477354012 epsilon 0.01 steps 1000\n",
      "episode:  42 score:  -65.1787456408469 epsilon 0.01 steps 1000\n",
      "episode:  43 score:  -126.59590983922715 epsilon 0.01 steps 1000\n",
      "episode:  44 score:  -79.69977935933056 epsilon 0.01 steps 1000\n",
      "episode:  45 score:  -223.40939606358052 epsilon 0.01 steps 113\n",
      "episode:  46 score:  -87.6958513073582 epsilon 0.01 steps 1000\n",
      "episode:  47 score:  -40.69670090249366 epsilon 0.01 steps 1000\n",
      "episode:  48 score:  -140.05628406342487 epsilon 0.01 steps 1000\n",
      "episode:  49 score:  -25.469351613346458 epsilon 0.01 steps 1000\n",
      "episode:  50 score:  -88.93445488071691 epsilon 0.01 steps 1000\n",
      "episode:  51 score:  -246.4061167894817 epsilon 0.01 steps 274\n",
      "episode:  52 score:  -36.1293815402835 epsilon 0.01 steps 1000\n",
      "episode:  53 score:  -100.61773147826774 epsilon 0.01 steps 1000\n",
      "episode:  54 score:  -87.17334288502133 epsilon 0.01 steps 1000\n",
      "episode:  55 score:  -88.74391173197672 epsilon 0.01 steps 1000\n",
      "episode:  56 score:  -51.637172439368754 epsilon 0.01 steps 1000\n",
      "episode:  57 score:  -69.9277837859579 epsilon 0.01 steps 1000\n",
      "episode:  58 score:  -133.9180262366701 epsilon 0.01 steps 1000\n",
      "episode:  59 score:  -94.59067274535022 epsilon 0.01 steps 1000\n",
      "episode:  60 score:  -65.33587073271056 epsilon 0.01 steps 1000\n",
      "episode:  61 score:  -91.52298192902893 epsilon 0.01 steps 1000\n",
      "episode:  62 score:  -128.23997755881837 epsilon 0.01 steps 1000\n",
      "episode:  63 score:  -81.02245735535557 epsilon 0.01 steps 1000\n",
      "episode:  64 score:  -86.28531541757579 epsilon 0.01 steps 1000\n",
      "episode:  65 score:  -127.27068995318469 epsilon 0.01 steps 1000\n",
      "episode:  66 score:  -45.2121064206448 epsilon 0.01 steps 1000\n",
      "episode:  67 score:  -48.555127018744116 epsilon 0.01 steps 1000\n",
      "episode:  68 score:  -123.87876187074383 epsilon 0.01 steps 1000\n",
      "episode:  69 score:  -60.4553777449415 epsilon 0.01 steps 1000\n",
      "episode:  70 score:  -131.47997247870842 epsilon 0.01 steps 1000\n",
      "episode:  71 score:  -101.29183299228264 epsilon 0.01 steps 1000\n",
      "episode:  72 score:  -111.0249173800021 epsilon 0.01 steps 1000\n",
      "episode:  73 score:  -92.6451021025039 epsilon 0.01 steps 1000\n",
      "episode:  74 score:  -83.70187975849394 epsilon 0.01 steps 1000\n",
      "episode:  75 score:  -402.5674370987223 epsilon 0.01 steps 858\n",
      "episode:  76 score:  -94.18146856134202 epsilon 0.01 steps 1000\n",
      "episode:  77 score:  -118.47300102641995 epsilon 0.01 steps 273\n",
      "episode:  78 score:  -122.69102820644865 epsilon 0.01 steps 1000\n",
      "episode:  79 score:  -106.14934914820023 epsilon 0.01 steps 1000\n",
      "episode:  80 score:  -112.58065323235073 epsilon 0.01 steps 1000\n",
      "episode:  81 score:  -86.41679762906888 epsilon 0.01 steps 1000\n",
      "episode:  82 score:  -56.39532534529945 epsilon 0.01 steps 1000\n",
      "episode:  83 score:  -81.40582053504582 epsilon 0.01 steps 1000\n",
      "episode:  84 score:  -85.43247069507724 epsilon 0.01 steps 1000\n",
      "episode:  85 score:  -56.582346772809785 epsilon 0.01 steps 116\n",
      "episode:  86 score:  -29.210709624475086 epsilon 0.01 steps 1000\n",
      "episode:  87 score:  -45.69829068898615 epsilon 0.01 steps 1000\n",
      "episode:  88 score:  -83.68522561551859 epsilon 0.01 steps 1000\n",
      "episode:  89 score:  -57.47933221341667 epsilon 0.01 steps 1000\n",
      "episode:  90 score:  -70.23938858073075 epsilon 0.01 steps 1000\n",
      "episode:  91 score:  -53.740833920825665 epsilon 0.01 steps 1000\n",
      "episode:  92 score:  -31.363355831869374 epsilon 0.01 steps 1000\n",
      "episode:  93 score:  -14.784945914691136 epsilon 0.01 steps 1000\n",
      "episode:  94 score:  -98.8509326797081 epsilon 0.01 steps 1000\n",
      "episode:  95 score:  -85.09076633350824 epsilon 0.01 steps 1000\n",
      "episode:  96 score:  -67.62742606148731 epsilon 0.01 steps 1000\n",
      "episode:  97 score:  -29.17987320705814 epsilon 0.01 steps 1000\n",
      "episode:  98 score:  -95.9030772208827 epsilon 0.01 steps 1000\n",
      "episode:  99 score:  -137.9347991964155 epsilon 0.01 steps 1000\n",
      "episode:  100 score:  -57.94800014428989 epsilon 0.01 steps 1000\n",
      "episode:  101 score:  10.377076286619367 epsilon 0.01 steps 1000\n",
      "episode:  102 score:  -66.68223177701084 epsilon 0.01 steps 1000\n",
      "episode:  103 score:  -107.67888017334083 epsilon 0.01 steps 1000\n",
      "episode:  104 score:  -47.87798501916843 epsilon 0.01 steps 1000\n",
      "episode:  105 score:  -90.86075143466002 epsilon 0.01 steps 1000\n",
      "episode:  106 score:  -89.41341738720696 epsilon 0.01 steps 1000\n",
      "episode:  107 score:  -62.84645009830541 epsilon 0.01 steps 1000\n",
      "episode:  108 score:  -90.46175267922175 epsilon 0.01 steps 1000\n",
      "episode:  109 score:  -78.13867841220392 epsilon 0.01 steps 148\n",
      "episode:  110 score:  -84.37722691051592 epsilon 0.01 steps 1000\n",
      "episode:  111 score:  -77.86158249729415 epsilon 0.01 steps 1000\n",
      "episode:  112 score:  -43.052761027945 epsilon 0.01 steps 1000\n",
      "episode:  113 score:  2.2970206162911815 epsilon 0.01 steps 1000\n",
      "episode:  114 score:  -75.58260575470007 epsilon 0.01 steps 1000\n",
      "episode:  115 score:  -90.25538658101331 epsilon 0.01 steps 1000\n",
      "episode:  116 score:  -23.19530297287584 epsilon 0.01 steps 1000\n",
      "episode:  117 score:  -84.87600981669355 epsilon 0.01 steps 1000\n",
      "episode:  118 score:  -32.301540121611296 epsilon 0.01 steps 1000\n",
      "episode:  119 score:  -88.61479356009343 epsilon 0.01 steps 1000\n",
      "episode:  120 score:  -29.990443277743086 epsilon 0.01 steps 1000\n",
      "episode:  121 score:  -83.19432185389574 epsilon 0.01 steps 1000\n",
      "episode:  122 score:  -64.68985372432434 epsilon 0.01 steps 1000\n",
      "episode:  123 score:  -129.67873393719208 epsilon 0.01 steps 1000\n",
      "episode:  124 score:  -54.514947683953935 epsilon 0.01 steps 1000\n",
      "episode:  125 score:  -82.12979406047786 epsilon 0.01 steps 1000\n",
      "episode:  126 score:  -75.96076088167894 epsilon 0.01 steps 1000\n",
      "episode:  127 score:  -90.2626198980539 epsilon 0.01 steps 1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode:  128 score:  -4.355837832270507 epsilon 0.01 steps 1000\n",
      "episode:  129 score:  -73.48774262077458 epsilon 0.01 steps 1000\n",
      "episode:  130 score:  -59.57773192848421 epsilon 0.01 steps 1000\n",
      "episode:  131 score:  -29.42821166543853 epsilon 0.01 steps 1000\n",
      "episode:  132 score:  -8.486920000578385 epsilon 0.01 steps 1000\n",
      "episode:  133 score:  -31.341419690203043 epsilon 0.01 steps 1000\n",
      "episode:  134 score:  -9.705483691007451 epsilon 0.01 steps 1000\n",
      "episode:  135 score:  -92.9857168081292 epsilon 0.01 steps 1000\n",
      "episode:  136 score:  -62.46891573969598 epsilon 0.01 steps 1000\n",
      "episode:  137 score:  -112.11220033255901 epsilon 0.01 steps 1000\n",
      "episode:  138 score:  -67.54577566499393 epsilon 0.01 steps 1000\n",
      "episode:  139 score:  -25.28226456638182 epsilon 0.01 steps 1000\n",
      "episode:  140 score:  -56.59300658526132 epsilon 0.01 steps 1000\n",
      "episode:  141 score:  -66.56057385697572 epsilon 0.01 steps 1000\n",
      "episode:  142 score:  -33.976579456698985 epsilon 0.01 steps 1000\n",
      "episode:  143 score:  -95.93378890002676 epsilon 0.01 steps 1000\n",
      "episode:  144 score:  -64.82187063475207 epsilon 0.01 steps 1000\n",
      "episode:  145 score:  -46.97038790727078 epsilon 0.01 steps 1000\n",
      "episode:  146 score:  -44.364178854525505 epsilon 0.01 steps 1000\n",
      "episode:  147 score:  -101.30727304630368 epsilon 0.01 steps 1000\n",
      "episode:  148 score:  -29.75691382619616 epsilon 0.01 steps 1000\n",
      "episode:  149 score:  -32.457614937759516 epsilon 0.01 steps 1000\n",
      "episode:  150 score:  -28.919347950114382 epsilon 0.01 steps 1000\n",
      "episode:  151 score:  -78.46945494149655 epsilon 0.01 steps 1000\n",
      "episode:  152 score:  -1.7487063450948415 epsilon 0.01 steps 1000\n",
      "episode:  153 score:  2.9474407180910216 epsilon 0.01 steps 1000\n",
      "episode:  154 score:  -72.26086723663177 epsilon 0.01 steps 1000\n",
      "episode:  155 score:  8.257875017579813 epsilon 0.01 steps 1000\n",
      "episode:  156 score:  -111.3277932858626 epsilon 0.01 steps 1000\n",
      "episode:  157 score:  -2.911318522015386 epsilon 0.01 steps 1000\n",
      "episode:  158 score:  -85.30321767108579 epsilon 0.01 steps 1000\n",
      "episode:  159 score:  -240.8997304558423 epsilon 0.01 steps 582\n",
      "episode:  160 score:  -7.077791581779514 epsilon 0.01 steps 1000\n",
      "episode:  161 score:  -54.44641045756432 epsilon 0.01 steps 1000\n",
      "episode:  162 score:  -64.3710331463024 epsilon 0.01 steps 1000\n",
      "episode:  163 score:  4.474167223737123 epsilon 0.01 steps 1000\n",
      "episode:  164 score:  25.168832130632182 epsilon 0.01 steps 1000\n",
      "episode:  165 score:  -97.63070732380517 epsilon 0.01 steps 1000\n",
      "episode:  166 score:  -51.933652522340765 epsilon 0.01 steps 1000\n",
      "episode:  167 score:  -118.36004319477694 epsilon 0.01 steps 1000\n",
      "episode:  168 score:  -56.76032102670446 epsilon 0.01 steps 1000\n",
      "episode:  169 score:  -30.657063170728748 epsilon 0.01 steps 1000\n",
      "episode:  170 score:  -74.29345813749802 epsilon 0.01 steps 1000\n",
      "episode:  171 score:  -66.79932243484474 epsilon 0.01 steps 1000\n",
      "episode:  172 score:  -86.8976829901925 epsilon 0.01 steps 1000\n",
      "episode:  173 score:  5.841534479936785 epsilon 0.01 steps 1000\n",
      "episode:  174 score:  -643.8304141436519 epsilon 0.01 steps 220\n",
      "episode:  175 score:  -11.226914382490783 epsilon 0.01 steps 1000\n",
      "episode:  176 score:  -112.16539012324573 epsilon 0.01 steps 1000\n",
      "episode:  177 score:  -93.10668627373208 epsilon 0.01 steps 1000\n",
      "episode:  178 score:  -1.31670370458752 epsilon 0.01 steps 1000\n",
      "episode:  179 score:  -38.774012211209715 epsilon 0.01 steps 1000\n",
      "episode:  180 score:  -79.72978369432961 epsilon 0.01 steps 1000\n",
      "episode:  181 score:  -84.97898732839958 epsilon 0.01 steps 1000\n",
      "episode:  182 score:  -116.19057778625289 epsilon 0.01 steps 1000\n",
      "episode:  183 score:  -80.00428650687896 epsilon 0.01 steps 1000\n",
      "episode:  184 score:  -110.71340647948553 epsilon 0.01 steps 1000\n",
      "episode:  185 score:  -16.665729952998696 epsilon 0.01 steps 1000\n",
      "episode:  186 score:  -106.10967721126806 epsilon 0.01 steps 1000\n",
      "episode:  187 score:  -106.87081754660822 epsilon 0.01 steps 1000\n",
      "episode:  188 score:  -230.50996616647214 epsilon 0.01 steps 826\n",
      "episode:  189 score:  -37.449147647950056 epsilon 0.01 steps 1000\n",
      "episode:  190 score:  -238.885258865156 epsilon 0.01 steps 693\n",
      "episode:  191 score:  -48.32919428851125 epsilon 0.01 steps 1000\n",
      "episode:  192 score:  -82.11501408602635 epsilon 0.01 steps 712\n",
      "episode:  193 score:  -170.25016494966525 epsilon 0.01 steps 52\n",
      "episode:  194 score:  -98.42888944098814 epsilon 0.01 steps 157\n",
      "episode:  195 score:  -70.04571833591632 epsilon 0.01 steps 1000\n",
      "episode:  196 score:  -97.59580167517852 epsilon 0.01 steps 1000\n",
      "episode:  197 score:  -28.67556944302876 epsilon 0.01 steps 1000\n",
      "episode:  198 score:  5.645846423202221 epsilon 0.01 steps 1000\n",
      "episode:  199 score:  -81.50012908522288 epsilon 0.01 steps 1000\n",
      "episode:  200 score:  -123.5940503860472 epsilon 0.01 steps 384\n",
      "episode:  201 score:  24.712624719591474 epsilon 0.01 steps 85\n",
      "episode:  202 score:  -118.07722092710918 epsilon 0.01 steps 278\n",
      "episode:  203 score:  -169.79793834294884 epsilon 0.01 steps 905\n",
      "episode:  204 score:  -43.087688373780736 epsilon 0.01 steps 1000\n",
      "episode:  205 score:  -4.499245373013214 epsilon 0.01 steps 1000\n",
      "episode:  206 score:  -157.52512556035066 epsilon 0.01 steps 160\n",
      "episode:  207 score:  -125.05626198679371 epsilon 0.01 steps 414\n",
      "episode:  208 score:  152.9607761208145 epsilon 0.01 steps 914\n",
      "episode:  209 score:  -97.72496875648976 epsilon 0.01 steps 461\n",
      "episode:  210 score:  -127.29709576546952 epsilon 0.01 steps 1000\n",
      "episode:  211 score:  -86.05204050771285 epsilon 0.01 steps 1000\n",
      "episode:  212 score:  -111.29423263437674 epsilon 0.01 steps 1000\n",
      "episode:  213 score:  -46.84280352304381 epsilon 0.01 steps 1000\n",
      "episode:  214 score:  -147.09816428884517 epsilon 0.01 steps 633\n",
      "episode:  215 score:  -240.70082643619634 epsilon 0.01 steps 847\n",
      "episode:  216 score:  -159.23938312409996 epsilon 0.01 steps 1000\n",
      "episode:  217 score:  -172.98340896185016 epsilon 0.01 steps 636\n",
      "episode:  218 score:  -53.085143939075294 epsilon 0.01 steps 1000\n",
      "episode:  219 score:  -79.46435946769175 epsilon 0.01 steps 71\n",
      "episode:  220 score:  -76.5792940653931 epsilon 0.01 steps 1000\n",
      "episode:  221 score:  -191.39943639703515 epsilon 0.01 steps 191\n",
      "episode:  222 score:  -92.57125977645283 epsilon 0.01 steps 1000\n",
      "episode:  223 score:  -103.86231330601754 epsilon 0.01 steps 1000\n",
      "episode:  224 score:  -56.29155021076616 epsilon 0.01 steps 1000\n",
      "episode:  225 score:  -177.20864620897282 epsilon 0.01 steps 275\n",
      "episode:  226 score:  -130.01555388864847 epsilon 0.01 steps 1000\n",
      "episode:  227 score:  -75.33676596388311 epsilon 0.01 steps 1000\n",
      "episode:  228 score:  -96.90432564799944 epsilon 0.01 steps 693\n",
      "episode:  229 score:  -106.2425650464413 epsilon 0.01 steps 846\n",
      "episode:  230 score:  -149.0557241181848 epsilon 0.01 steps 60\n",
      "episode:  231 score:  -206.174662664854 epsilon 0.01 steps 74\n",
      "episode:  232 score:  -80.30332901996618 epsilon 0.01 steps 1000\n",
      "episode:  233 score:  -78.3911321235658 epsilon 0.01 steps 1000\n",
      "episode:  234 score:  -45.42704513084778 epsilon 0.01 steps 1000\n",
      "episode:  235 score:  -101.5432841364792 epsilon 0.01 steps 53\n",
      "episode:  236 score:  -208.97697710294653 epsilon 0.01 steps 59\n",
      "episode:  237 score:  -160.76703059200585 epsilon 0.01 steps 379\n",
      "episode:  238 score:  -57.05543919962155 epsilon 0.01 steps 1000\n",
      "episode:  239 score:  -58.360778601877215 epsilon 0.01 steps 1000\n",
      "episode:  240 score:  -32.54546589968904 epsilon 0.01 steps 1000\n",
      "episode:  241 score:  -142.24982894471657 epsilon 0.01 steps 1000\n",
      "episode:  242 score:  -76.23700409076399 epsilon 0.01 steps 1000\n",
      "episode:  243 score:  -65.67064704482036 epsilon 0.01 steps 1000\n",
      "episode:  244 score:  -176.29793549474047 epsilon 0.01 steps 632\n",
      "episode:  245 score:  -130.1785598040326 epsilon 0.01 steps 1000\n",
      "episode:  246 score:  -90.3811990651366 epsilon 0.01 steps 1000\n",
      "episode:  247 score:  -104.89663034352435 epsilon 0.01 steps 80\n",
      "episode:  248 score:  -49.65147144742781 epsilon 0.01 steps 1000\n",
      "episode:  249 score:  -77.0619746474959 epsilon 0.01 steps 225\n",
      "episode:  250 score:  -84.42116784315047 epsilon 0.01 steps 261\n",
      "episode:  251 score:  -152.84160166622107 epsilon 0.01 steps 271\n",
      "episode:  252 score:  -126.67319428344396 epsilon 0.01 steps 1000\n",
      "episode:  253 score:  -223.64068748577046 epsilon 0.01 steps 688\n",
      "episode:  254 score:  -105.68069047492057 epsilon 0.01 steps 1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode:  255 score:  -126.60780945787616 epsilon 0.01 steps 1000\n",
      "episode:  256 score:  -68.9734468328711 epsilon 0.01 steps 1000\n",
      "episode:  257 score:  -22.687267841568875 epsilon 0.01 steps 1000\n",
      "episode:  258 score:  -186.94515392497345 epsilon 0.01 steps 825\n",
      "episode:  259 score:  -11.160244719291773 epsilon 0.01 steps 1000\n",
      "episode:  260 score:  -125.87464276702424 epsilon 0.01 steps 1000\n",
      "episode:  261 score:  -87.95091020088252 epsilon 0.01 steps 1000\n",
      "episode:  262 score:  -112.905239250243 epsilon 0.01 steps 1000\n",
      "episode:  263 score:  -87.16999191230859 epsilon 0.01 steps 1000\n",
      "episode:  264 score:  -52.88632365069614 epsilon 0.01 steps 1000\n",
      "episode:  265 score:  -118.37844387522982 epsilon 0.01 steps 1000\n",
      "episode:  266 score:  -86.02556002797198 epsilon 0.01 steps 1000\n",
      "episode:  267 score:  -101.98531959347866 epsilon 0.01 steps 1000\n",
      "episode:  268 score:  -132.1208501184523 epsilon 0.01 steps 743\n",
      "episode:  269 score:  -44.40616671113344 epsilon 0.01 steps 1000\n",
      "episode:  270 score:  -64.29551382256388 epsilon 0.01 steps 1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function WeakKeyDictionary.__init__.<locals>.remove at 0x000002637B55C168>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Miniconda3\\envs\\tensorflow\\lib\\weakref.py\", line 359, in remove\n",
      "    self = selfref()\n",
      "KeyboardInterrupt: \n",
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Miniconda3\\envs\\tensorflow\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3417, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-11-2ce8589acebc>\", line 10, in <module>\n",
      "    action=agent.agent_step(state,reward,terminal)\n",
      "  File \"<ipython-input-7-f0a14aa2cbe8>\", line 74, in agent_step\n",
      "    action = self.policy(state)\n",
      "  File \"<ipython-input-7-f0a14aa2cbe8>\", line 46, in policy\n",
      "    action_values =self.model.predict(state)\n",
      "  File \"C:\\ProgramData\\Miniconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\", line 1013, in predict\n",
      "    use_multiprocessing=use_multiprocessing)\n",
      "  File \"C:\\ProgramData\\Miniconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\", line 498, in predict\n",
      "    workers=workers, use_multiprocessing=use_multiprocessing, **kwargs)\n",
      "  File \"C:\\ProgramData\\Miniconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\", line 475, in _model_iteration\n",
      "    total_epochs=1)\n",
      "  File \"C:\\ProgramData\\Miniconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\", line 128, in run_one_epoch\n",
      "    batch_outs = execution_function(iterator)\n",
      "  File \"C:\\ProgramData\\Miniconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2_utils.py\", line 98, in execution_function\n",
      "    distributed_function(input_fn))\n",
      "  File \"C:\\ProgramData\\Miniconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\eager\\def_function.py\", line 568, in __call__\n",
      "    result = self._call(*args, **kwds)\n",
      "  File \"C:\\ProgramData\\Miniconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\eager\\def_function.py\", line 606, in _call\n",
      "    results = self._stateful_fn(*args, **kwds)\n",
      "  File \"C:\\ProgramData\\Miniconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\", line 2363, in __call__\n",
      "    return graph_function._filtered_call(args, kwargs)  # pylint: disable=protected-access\n",
      "  File \"C:\\ProgramData\\Miniconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\", line 1611, in _filtered_call\n",
      "    self.captured_inputs)\n",
      "  File \"C:\\ProgramData\\Miniconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\", line 1692, in _call_flat\n",
      "    ctx, args, cancellation_manager=cancellation_manager))\n",
      "  File \"C:\\ProgramData\\Miniconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\", line 545, in call\n",
      "    ctx=ctx)\n",
      "  File \"C:\\ProgramData\\Miniconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\eager\\execute.py\", line 61, in quick_execute\n",
      "    num_outputs)\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Miniconda3\\envs\\tensorflow\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2044, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Miniconda3\\envs\\tensorflow\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1169, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"C:\\ProgramData\\Miniconda3\\envs\\tensorflow\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 316, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Miniconda3\\envs\\tensorflow\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 350, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"C:\\ProgramData\\Miniconda3\\envs\\tensorflow\\lib\\inspect.py\", line 1502, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"C:\\ProgramData\\Miniconda3\\envs\\tensorflow\\lib\\inspect.py\", line 1460, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"C:\\ProgramData\\Miniconda3\\envs\\tensorflow\\lib\\inspect.py\", line 696, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"C:\\ProgramData\\Miniconda3\\envs\\tensorflow\\lib\\inspect.py\", line 733, in getmodule\n",
      "    if ismodule(module) and hasattr(module, '__file__'):\n",
      "  File \"C:\\ProgramData\\Miniconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\__init__.py\", line 50, in __getattr__\n",
      "    module = self._load()\n",
      "  File \"C:\\ProgramData\\Miniconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\__init__.py\", line 44, in _load\n",
      "    module = _importlib.import_module(self.__name__)\n",
      "  File \"C:\\ProgramData\\Miniconda3\\envs\\tensorflow\\lib\\importlib\\__init__.py\", line 127, in import_module\n",
      "    return _bootstrap._gcd_import(name[level:], package, level)\n",
      "  File \"<frozen importlib._bootstrap>\", line 1006, in _gcd_import\n",
      "  File \"<frozen importlib._bootstrap>\", line 983, in _find_and_load\n",
      "  File \"<frozen importlib._bootstrap>\", line 967, in _find_and_load_unlocked\n",
      "  File \"<frozen importlib._bootstrap>\", line 677, in _load_unlocked\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 728, in exec_module\n",
      "  File \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\n",
      "  File \"C:\\ProgramData\\Miniconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\_api\\v2\\compat\\__init__.py\", line 40, in <module>\n",
      "    from . import v2\n",
      "  File \"C:\\ProgramData\\Miniconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\_api\\v2\\compat\\v2\\__init__.py\", line 37, in <module>\n",
      "    from . import distribute\n",
      "  File \"C:\\ProgramData\\Miniconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\_api\\v2\\compat\\v2\\distribute\\__init__.py\", line 88, in <module>\n",
      "    from . import experimental\n",
      "  File \"<frozen importlib._bootstrap>\", line 983, in _find_and_load\n",
      "  File \"<frozen importlib._bootstrap>\", line 963, in _find_and_load_unlocked\n",
      "  File \"<frozen importlib._bootstrap>\", line 906, in _find_spec\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 1280, in find_spec\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 1252, in _get_spec\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 1383, in find_spec\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 95, in _path_isfile\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 87, in _path_is_mode_type\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 81, in _path_stat\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "object of type 'NoneType' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "    \u001b[1;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "\u001b[1;32m<ipython-input-11-2ce8589acebc>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m             \u001b[0mterminal\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m         \u001b[0maction\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0magent\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0magent_step\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mreward\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mterminal\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0magent\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mepsilon\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0mMIN_EPSILON\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-7-f0a14aa2cbe8>\u001b[0m in \u001b[0;36magent_step\u001b[1;34m(self, state, reward, terminal)\u001b[0m\n\u001b[0;32m     73\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 74\u001b[1;33m         \u001b[0maction\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpolicy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     75\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-7-f0a14aa2cbe8>\u001b[0m in \u001b[0;36mpolicy\u001b[1;34m(self, state)\u001b[0m\n\u001b[0;32m     45\u001b[0m         \"\"\"\n\u001b[1;32m---> 46\u001b[1;33m         \u001b[0maction_values\u001b[0m \u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     47\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muniform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mepsilon\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0maction_values\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Miniconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1012\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1013\u001b[1;33m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[0;32m   1014\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Miniconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, model, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    497\u001b[0m         \u001b[0msteps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_queue_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 498\u001b[1;33m         workers=workers, use_multiprocessing=use_multiprocessing, **kwargs)\n\u001b[0m\u001b[0;32m    499\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Miniconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36m_model_iteration\u001b[1;34m(self, model, mode, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    474\u001b[0m               \u001b[0mtraining_context\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtraining_context\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 475\u001b[1;33m               total_epochs=1)\n\u001b[0m\u001b[0;32m    476\u001b[0m           \u001b[0mcbks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmake_logs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Miniconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36mrun_one_epoch\u001b[1;34m(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs)\u001b[0m\n\u001b[0;32m    127\u001b[0m       \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 128\u001b[1;33m         \u001b[0mbatch_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    129\u001b[0m       \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mStopIteration\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Miniconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2_utils.py\u001b[0m in \u001b[0;36mexecution_function\u001b[1;34m(input_fn)\u001b[0m\n\u001b[0;32m     97\u001b[0m     return nest.map_structure(_non_none_constant_value,\n\u001b[1;32m---> 98\u001b[1;33m                               distributed_function(input_fn))\n\u001b[0m\u001b[0;32m     99\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Miniconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    567\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 568\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    569\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Miniconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    605\u001b[0m       \u001b[1;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 606\u001b[1;33m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    607\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_created_variables\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Miniconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2362\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2363\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2364\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Miniconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   1610\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[1;32m-> 1611\u001b[1;33m         self.captured_inputs)\n\u001b[0m\u001b[0;32m   1612\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Miniconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1691\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[1;32m-> 1692\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[0;32m   1693\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[1;32mC:\\ProgramData\\Miniconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    544\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"executor_type\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"config_proto\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 545\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    546\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Miniconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 61\u001b[1;33m                                                num_outputs)\n\u001b[0m\u001b[0;32m     62\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32mC:\\ProgramData\\Miniconda3\\envs\\tensorflow\\lib\\site-packages\\IPython\\core\\interactiveshell.py\u001b[0m in \u001b[0;36mshowtraceback\u001b[1;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[0;32m   2043\u001b[0m                         \u001b[1;31m# in the engines. This should return a list of strings.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2044\u001b[1;33m                         \u001b[0mstb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_render_traceback_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2045\u001b[0m                     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'KeyboardInterrupt' object has no attribute '_render_traceback_'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "    \u001b[1;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Miniconda3\\envs\\tensorflow\\lib\\site-packages\\IPython\\core\\interactiveshell.py\u001b[0m in \u001b[0;36mshowtraceback\u001b[1;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[0;32m   2045\u001b[0m                     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2046\u001b[0m                         stb = self.InteractiveTB.structured_traceback(etype,\n\u001b[1;32m-> 2047\u001b[1;33m                                             value, tb, tb_offset=tb_offset)\n\u001b[0m\u001b[0;32m   2048\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2049\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_showtraceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0metype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Miniconda3\\envs\\tensorflow\\lib\\site-packages\\IPython\\core\\ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[1;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[0;32m   1434\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1435\u001b[0m         return FormattedTB.structured_traceback(\n\u001b[1;32m-> 1436\u001b[1;33m             self, etype, value, tb, tb_offset, number_of_lines_of_context)\n\u001b[0m\u001b[0;32m   1437\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1438\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Miniconda3\\envs\\tensorflow\\lib\\site-packages\\IPython\\core\\ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[1;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[0;32m   1334\u001b[0m             \u001b[1;31m# Verbose modes need a full traceback\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1335\u001b[0m             return VerboseTB.structured_traceback(\n\u001b[1;32m-> 1336\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0metype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtb_offset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnumber_of_lines_of_context\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1337\u001b[0m             )\n\u001b[0;32m   1338\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'Minimal'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Miniconda3\\envs\\tensorflow\\lib\\site-packages\\IPython\\core\\ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[1;34m(self, etype, evalue, etb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[0;32m   1191\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1192\u001b[0m         formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n\u001b[1;32m-> 1193\u001b[1;33m                                                                tb_offset)\n\u001b[0m\u001b[0;32m   1194\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1195\u001b[0m         \u001b[0mcolors\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mColors\u001b[0m  \u001b[1;31m# just a shorthand + quicker name lookup\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Miniconda3\\envs\\tensorflow\\lib\\site-packages\\IPython\\core\\ultratb.py\u001b[0m in \u001b[0;36mformat_exception_as_a_whole\u001b[1;34m(self, etype, evalue, etb, number_of_lines_of_context, tb_offset)\u001b[0m\n\u001b[0;32m   1148\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1149\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1150\u001b[1;33m         \u001b[0mlast_unique\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrecursion_repeat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfind_recursion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0morig_etype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrecords\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1151\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1152\u001b[0m         \u001b[0mframes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat_records\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrecords\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlast_unique\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrecursion_repeat\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Miniconda3\\envs\\tensorflow\\lib\\site-packages\\IPython\\core\\ultratb.py\u001b[0m in \u001b[0;36mfind_recursion\u001b[1;34m(etype, value, records)\u001b[0m\n\u001b[0;32m    449\u001b[0m     \u001b[1;31m# first frame (from in to out) that looks different.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    450\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mis_recursion_error\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0metype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrecords\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 451\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrecords\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    452\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    453\u001b[0m     \u001b[1;31m# Select filename, lineno, func_name to track frames with\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: object of type 'NoneType' has no len()"
     ]
    }
   ],
   "source": [
    "for episode in range(0,500):\n",
    "    action=agent.agent_start()\n",
    "    terminal=0\n",
    "    while terminal!=1:\n",
    "        state,reward,terminal,info=env.step(action)\n",
    "        if terminal==True:\n",
    "            terminal=1\n",
    "        else:\n",
    "            terminal=0\n",
    "        action=agent.agent_step(state,reward,terminal)\n",
    "        if agent.epsilon > MIN_EPSILON:\n",
    "            agent.epsilon *= EPSILON_DECAY\n",
    "            agent.epsilon = max(MIN_EPSILON,agent.epsilon)\n",
    "    reward = agent.agent_message('get_sum_reward')\n",
    "    reward_episode.append(reward)\n",
    "    no_episodes.append(episode)\n",
    "    episode_steps.append(agent.episode_steps)\n",
    "    eps_history.append(agent.epsilon)\n",
    "    print('episode: ', episode,'score: ',reward,\n",
    "            'epsilon %.2f' % agent.epsilon, 'steps', agent.episode_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "840.5940959409594"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "np.mean(episode_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[91,\n",
       " 86,\n",
       " 82,\n",
       " 133,\n",
       " 106,\n",
       " 106,\n",
       " 157,\n",
       " 60,\n",
       " 93,\n",
       " 81,\n",
       " 127,\n",
       " 141,\n",
       " 166,\n",
       " 71,\n",
       " 102,\n",
       " 204,\n",
       " 206,\n",
       " 132,\n",
       " 563,\n",
       " 1000,\n",
       " 1000,\n",
       " 1000,\n",
       " 941,\n",
       " 1000,\n",
       " 1000,\n",
       " 278,\n",
       " 627,\n",
       " 1000,\n",
       " 1000,\n",
       " 1000,\n",
       " 1000,\n",
       " 1000,\n",
       " 1000,\n",
       " 1000,\n",
       " 1000,\n",
       " 1000,\n",
       " 1000,\n",
       " 1000,\n",
       " 1000,\n",
       " 81,\n",
       " 1000,\n",
       " 1000,\n",
       " 1000,\n",
       " 1000,\n",
       " 1000,\n",
       " 113,\n",
       " 1000,\n",
       " 1000,\n",
       " 1000,\n",
       " 1000,\n",
       " 1000,\n",
       " 274,\n",
       " 1000,\n",
       " 1000,\n",
       " 1000,\n",
       " 1000,\n",
       " 1000,\n",
       " 1000,\n",
       " 1000,\n",
       " 1000,\n",
       " 1000,\n",
       " 1000,\n",
       " 1000,\n",
       " 1000,\n",
       " 1000,\n",
       " 1000,\n",
       " 1000,\n",
       " 1000,\n",
       " 1000,\n",
       " 1000,\n",
       " 1000,\n",
       " 1000,\n",
       " 1000,\n",
       " 1000,\n",
       " 1000,\n",
       " 858,\n",
       " 1000,\n",
       " 273,\n",
       " 1000,\n",
       " 1000,\n",
       " 1000,\n",
       " 1000,\n",
       " 1000,\n",
       " 1000,\n",
       " 1000,\n",
       " 116,\n",
       " 1000,\n",
       " 1000,\n",
       " 1000,\n",
       " 1000,\n",
       " 1000,\n",
       " 1000,\n",
       " 1000,\n",
       " 1000,\n",
       " 1000,\n",
       " 1000,\n",
       " 1000,\n",
       " 1000,\n",
       " 1000,\n",
       " 1000,\n",
       " 1000,\n",
       " 1000,\n",
       " 1000,\n",
       " 1000,\n",
       " 1000,\n",
       " 1000,\n",
       " 1000,\n",
       " 1000,\n",
       " 1000,\n",
       " 148,\n",
       " 1000,\n",
       " 1000,\n",
       " 1000,\n",
       " 1000,\n",
       " 1000,\n",
       " 1000,\n",
       " 1000,\n",
       " 1000,\n",
       " 1000,\n",
       " 1000,\n",
       " 1000,\n",
       " 1000,\n",
       " 1000,\n",
       " 1000,\n",
       " 1000,\n",
       " 1000,\n",
       " 1000,\n",
       " 1000,\n",
       " 1000,\n",
       " 1000,\n",
       " 1000,\n",
       " 1000,\n",
       " 1000,\n",
       " 1000,\n",
       " 1000,\n",
       " 1000,\n",
       " 1000,\n",
       " 1000,\n",
       " 1000,\n",
       " 1000,\n",
       " 1000,\n",
       " 1000,\n",
       " 1000,\n",
       " 1000,\n",
       " 1000,\n",
       " 1000,\n",
       " 1000,\n",
       " 1000,\n",
       " 1000,\n",
       " 1000,\n",
       " 1000,\n",
       " 1000,\n",
       " 1000,\n",
       " 1000,\n",
       " 1000,\n",
       " 1000,\n",
       " 1000,\n",
       " 1000,\n",
       " 1000,\n",
       " 582,\n",
       " 1000,\n",
       " 1000,\n",
       " 1000,\n",
       " 1000,\n",
       " 1000,\n",
       " 1000,\n",
       " 1000,\n",
       " 1000,\n",
       " 1000,\n",
       " 1000,\n",
       " 1000,\n",
       " 1000,\n",
       " 1000,\n",
       " 1000,\n",
       " 220,\n",
       " 1000,\n",
       " 1000,\n",
       " 1000,\n",
       " 1000,\n",
       " 1000,\n",
       " 1000,\n",
       " 1000,\n",
       " 1000,\n",
       " 1000,\n",
       " 1000,\n",
       " 1000,\n",
       " 1000,\n",
       " 1000,\n",
       " 826,\n",
       " 1000,\n",
       " 693,\n",
       " 1000,\n",
       " 712,\n",
       " 52,\n",
       " 157,\n",
       " 1000,\n",
       " 1000,\n",
       " 1000,\n",
       " 1000,\n",
       " 1000,\n",
       " 384,\n",
       " 85,\n",
       " 278,\n",
       " 905,\n",
       " 1000,\n",
       " 1000,\n",
       " 160,\n",
       " 414,\n",
       " 914,\n",
       " 461,\n",
       " 1000,\n",
       " 1000,\n",
       " 1000,\n",
       " 1000,\n",
       " 633,\n",
       " 847,\n",
       " 1000,\n",
       " 636,\n",
       " 1000,\n",
       " 71,\n",
       " 1000,\n",
       " 191,\n",
       " 1000,\n",
       " 1000,\n",
       " 1000,\n",
       " 275,\n",
       " 1000,\n",
       " 1000,\n",
       " 693,\n",
       " 846,\n",
       " 60,\n",
       " 74,\n",
       " 1000,\n",
       " 1000,\n",
       " 1000,\n",
       " 53,\n",
       " 59,\n",
       " 379,\n",
       " 1000,\n",
       " 1000,\n",
       " 1000,\n",
       " 1000,\n",
       " 1000,\n",
       " 1000,\n",
       " 632,\n",
       " 1000,\n",
       " 1000,\n",
       " 80,\n",
       " 1000,\n",
       " 225,\n",
       " 261,\n",
       " 271,\n",
       " 1000,\n",
       " 688,\n",
       " 1000,\n",
       " 1000,\n",
       " 1000,\n",
       " 1000,\n",
       " 825,\n",
       " 1000,\n",
       " 1000,\n",
       " 1000,\n",
       " 1000,\n",
       " 1000,\n",
       " 1000,\n",
       " 1000,\n",
       " 1000,\n",
       " 1000,\n",
       " 743,\n",
       " 1000,\n",
       " 1000]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "episode_steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-115.17095984196763,\n",
       " -94.78368746910266,\n",
       " -271.6819623466136,\n",
       " -44.363561492489836,\n",
       " -140.9167389738966,\n",
       " -270.37136693209436,\n",
       " 13.416376741490794,\n",
       " -96.17115855063275,\n",
       " 11.958474636660242,\n",
       " -505.7816597670661,\n",
       " -471.3396999477431,\n",
       " -147.31030553000284,\n",
       " -167.71087189354458,\n",
       " -146.8974771557461,\n",
       " -173.39529418595123,\n",
       " -175.19281870932997,\n",
       " -114.28528186955161,\n",
       " -31.87208890419734,\n",
       " -149.57195642219034,\n",
       " -91.87271411378522,\n",
       " -156.5597962027561,\n",
       " -88.5205424594497,\n",
       " -515.1322744500776,\n",
       " -190.44588694374966,\n",
       " -73.82752554699451,\n",
       " -56.873707463841676,\n",
       " -190.15513904697772,\n",
       " -122.69529526037017,\n",
       " -75.44828332553858,\n",
       " -63.57068200864758,\n",
       " -110.51693021433941,\n",
       " -48.06230828928637,\n",
       " -43.33477619054013,\n",
       " -51.158677202506524,\n",
       " -115.23811558064642,\n",
       " -25.75519711984166,\n",
       " -113.74743731294333,\n",
       " -81.92497475833127,\n",
       " -21.232544839780584,\n",
       " -323.8692243556696,\n",
       " -42.36902778945438,\n",
       " -87.33420477354012,\n",
       " -65.1787456408469,\n",
       " -126.59590983922715,\n",
       " -79.69977935933056,\n",
       " -223.40939606358052,\n",
       " -87.6958513073582,\n",
       " -40.69670090249366,\n",
       " -140.05628406342487,\n",
       " -25.469351613346458,\n",
       " -88.93445488071691,\n",
       " -246.4061167894817,\n",
       " -36.1293815402835,\n",
       " -100.61773147826774,\n",
       " -87.17334288502133,\n",
       " -88.74391173197672,\n",
       " -51.637172439368754,\n",
       " -69.9277837859579,\n",
       " -133.9180262366701,\n",
       " -94.59067274535022,\n",
       " -65.33587073271056,\n",
       " -91.52298192902893,\n",
       " -128.23997755881837,\n",
       " -81.02245735535557,\n",
       " -86.28531541757579,\n",
       " -127.27068995318469,\n",
       " -45.2121064206448,\n",
       " -48.555127018744116,\n",
       " -123.87876187074383,\n",
       " -60.4553777449415,\n",
       " -131.47997247870842,\n",
       " -101.29183299228264,\n",
       " -111.0249173800021,\n",
       " -92.6451021025039,\n",
       " -83.70187975849394,\n",
       " -402.5674370987223,\n",
       " -94.18146856134202,\n",
       " -118.47300102641995,\n",
       " -122.69102820644865,\n",
       " -106.14934914820023,\n",
       " -112.58065323235073,\n",
       " -86.41679762906888,\n",
       " -56.39532534529945,\n",
       " -81.40582053504582,\n",
       " -85.43247069507724,\n",
       " -56.582346772809785,\n",
       " -29.210709624475086,\n",
       " -45.69829068898615,\n",
       " -83.68522561551859,\n",
       " -57.47933221341667,\n",
       " -70.23938858073075,\n",
       " -53.740833920825665,\n",
       " -31.363355831869374,\n",
       " -14.784945914691136,\n",
       " -98.8509326797081,\n",
       " -85.09076633350824,\n",
       " -67.62742606148731,\n",
       " -29.17987320705814,\n",
       " -95.9030772208827,\n",
       " -137.9347991964155,\n",
       " -57.94800014428989,\n",
       " 10.377076286619367,\n",
       " -66.68223177701084,\n",
       " -107.67888017334083,\n",
       " -47.87798501916843,\n",
       " -90.86075143466002,\n",
       " -89.41341738720696,\n",
       " -62.84645009830541,\n",
       " -90.46175267922175,\n",
       " -78.13867841220392,\n",
       " -84.37722691051592,\n",
       " -77.86158249729415,\n",
       " -43.052761027945,\n",
       " 2.2970206162911815,\n",
       " -75.58260575470007,\n",
       " -90.25538658101331,\n",
       " -23.19530297287584,\n",
       " -84.87600981669355,\n",
       " -32.301540121611296,\n",
       " -88.61479356009343,\n",
       " -29.990443277743086,\n",
       " -83.19432185389574,\n",
       " -64.68985372432434,\n",
       " -129.67873393719208,\n",
       " -54.514947683953935,\n",
       " -82.12979406047786,\n",
       " -75.96076088167894,\n",
       " -90.2626198980539,\n",
       " -4.355837832270507,\n",
       " -73.48774262077458,\n",
       " -59.57773192848421,\n",
       " -29.42821166543853,\n",
       " -8.486920000578385,\n",
       " -31.341419690203043,\n",
       " -9.705483691007451,\n",
       " -92.9857168081292,\n",
       " -62.46891573969598,\n",
       " -112.11220033255901,\n",
       " -67.54577566499393,\n",
       " -25.28226456638182,\n",
       " -56.59300658526132,\n",
       " -66.56057385697572,\n",
       " -33.976579456698985,\n",
       " -95.93378890002676,\n",
       " -64.82187063475207,\n",
       " -46.97038790727078,\n",
       " -44.364178854525505,\n",
       " -101.30727304630368,\n",
       " -29.75691382619616,\n",
       " -32.457614937759516,\n",
       " -28.919347950114382,\n",
       " -78.46945494149655,\n",
       " -1.7487063450948415,\n",
       " 2.9474407180910216,\n",
       " -72.26086723663177,\n",
       " 8.257875017579813,\n",
       " -111.3277932858626,\n",
       " -2.911318522015386,\n",
       " -85.30321767108579,\n",
       " -240.8997304558423,\n",
       " -7.077791581779514,\n",
       " -54.44641045756432,\n",
       " -64.3710331463024,\n",
       " 4.474167223737123,\n",
       " 25.168832130632182,\n",
       " -97.63070732380517,\n",
       " -51.933652522340765,\n",
       " -118.36004319477694,\n",
       " -56.76032102670446,\n",
       " -30.657063170728748,\n",
       " -74.29345813749802,\n",
       " -66.79932243484474,\n",
       " -86.8976829901925,\n",
       " 5.841534479936785,\n",
       " -643.8304141436519,\n",
       " -11.226914382490783,\n",
       " -112.16539012324573,\n",
       " -93.10668627373208,\n",
       " -1.31670370458752,\n",
       " -38.774012211209715,\n",
       " -79.72978369432961,\n",
       " -84.97898732839958,\n",
       " -116.19057778625289,\n",
       " -80.00428650687896,\n",
       " -110.71340647948553,\n",
       " -16.665729952998696,\n",
       " -106.10967721126806,\n",
       " -106.87081754660822,\n",
       " -230.50996616647214,\n",
       " -37.449147647950056,\n",
       " -238.885258865156,\n",
       " -48.32919428851125,\n",
       " -82.11501408602635,\n",
       " -170.25016494966525,\n",
       " -98.42888944098814,\n",
       " -70.04571833591632,\n",
       " -97.59580167517852,\n",
       " -28.67556944302876,\n",
       " 5.645846423202221,\n",
       " -81.50012908522288,\n",
       " -123.5940503860472,\n",
       " 24.712624719591474,\n",
       " -118.07722092710918,\n",
       " -169.79793834294884,\n",
       " -43.087688373780736,\n",
       " -4.499245373013214,\n",
       " -157.52512556035066,\n",
       " -125.05626198679371,\n",
       " 152.9607761208145,\n",
       " -97.72496875648976,\n",
       " -127.29709576546952,\n",
       " -86.05204050771285,\n",
       " -111.29423263437674,\n",
       " -46.84280352304381,\n",
       " -147.09816428884517,\n",
       " -240.70082643619634,\n",
       " -159.23938312409996,\n",
       " -172.98340896185016,\n",
       " -53.085143939075294,\n",
       " -79.46435946769175,\n",
       " -76.5792940653931,\n",
       " -191.39943639703515,\n",
       " -92.57125977645283,\n",
       " -103.86231330601754,\n",
       " -56.29155021076616,\n",
       " -177.20864620897282,\n",
       " -130.01555388864847,\n",
       " -75.33676596388311,\n",
       " -96.90432564799944,\n",
       " -106.2425650464413,\n",
       " -149.0557241181848,\n",
       " -206.174662664854,\n",
       " -80.30332901996618,\n",
       " -78.3911321235658,\n",
       " -45.42704513084778,\n",
       " -101.5432841364792,\n",
       " -208.97697710294653,\n",
       " -160.76703059200585,\n",
       " -57.05543919962155,\n",
       " -58.360778601877215,\n",
       " -32.54546589968904,\n",
       " -142.24982894471657,\n",
       " -76.23700409076399,\n",
       " -65.67064704482036,\n",
       " -176.29793549474047,\n",
       " -130.1785598040326,\n",
       " -90.3811990651366,\n",
       " -104.89663034352435,\n",
       " -49.65147144742781,\n",
       " -77.0619746474959,\n",
       " -84.42116784315047,\n",
       " -152.84160166622107,\n",
       " -126.67319428344396,\n",
       " -223.64068748577046,\n",
       " -105.68069047492057,\n",
       " -126.60780945787616,\n",
       " -68.9734468328711,\n",
       " -22.687267841568875,\n",
       " -186.94515392497345,\n",
       " -11.160244719291773,\n",
       " -125.87464276702424,\n",
       " -87.95091020088252,\n",
       " -112.905239250243,\n",
       " -87.16999191230859,\n",
       " -52.88632365069614,\n",
       " -118.37844387522982,\n",
       " -86.02556002797198,\n",
       " -101.98531959347866,\n",
       " -132.1208501184523,\n",
       " -44.40616671113344,\n",
       " -64.29551382256388]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reward_episode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow] *",
   "language": "python",
   "name": "conda-env-tensorflow-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
